{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Value_LAB_Challenge.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdYcd5giZ2IF",
        "colab_type": "text"
      },
      "source": [
        "### Getting the Dataset and Pre-Requisite files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1m-l4UACnQ4",
        "colab_type": "code",
        "outputId": "e1e8539f-51ae-42ea-80ea-6ec9da75d8b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!unzip 92a4172ee04e11e9.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  92a4172ee04e11e9.zip\n",
            "   creating: DataSet/\n",
            "  inflating: DataSet/Results.csv     \n",
            "  inflating: DataSet/Train.csv       \n",
            "  inflating: DataSet/readme.md       \n",
            "  inflating: DataSet/Sample_Submission.csv  \n",
            "  inflating: DataSet/Test.csv        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbxbbcaaDfo2",
        "colab_type": "code",
        "outputId": "f1d15b67-f635-4650-e90a-171f9fad018a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "! kaggle"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 6, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/api/kaggle_api_extended.py\", line 146, in authenticate\n",
            "    self.config_file, self.config_dir))\n",
            "IOError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XonU9JlfD2oY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! cp kaggle.json /root/.kaggle/kaggle.json\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVoxU83dD2r7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DawN9lpSDflZ",
        "colab_type": "code",
        "outputId": "24a7a16f-72f3-4d11-c90c-35527eaeee58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!kaggle datasets download -d watts2/glove6b50dtxt\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading glove6b50dtxt.zip to /content\n",
            " 96% 65.0M/67.7M [00:01<00:00, 22.6MB/s]\n",
            "100% 67.7M/67.7M [00:01<00:00, 42.6MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "At702lkeD2vv",
        "colab_type": "code",
        "outputId": "f543828b-d1d5-42de-e860-e056b8c3f5d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!unzip glove6b50dtxt.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove6b50dtxt.zip\n",
            "  inflating: glove.6B.50d.txt        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_Ck2Q3iaCYH",
        "colab_type": "text"
      },
      "source": [
        "### Importing the necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "augvOir2Cvz7",
        "colab_type": "code",
        "outputId": "5a83c8b5-def0-4253-df23-da5157c9d309",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import *\n",
        "from keras.models import Sequential,Model\n",
        "import re\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l09R3IybaIy-",
        "colab_type": "text"
      },
      "source": [
        "### Looking at the Train and Test files to study"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9-I03C5Cv4H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(\"DataSet/Train.csv\")\n",
        "test = pd.read_csv(\"DataSet/Test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWLisqVjCv7k",
        "colab_type": "code",
        "outputId": "ace09775-13b0-4016-a694-06c8d55f4f1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer_text</th>\n",
              "      <th>distractor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Meals can be served</td>\n",
              "      <td>in rooms at 9:00 p. m.</td>\n",
              "      <td>'outside the room at 3:00 p. m.', 'in the dini...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>It can be inferred from the passage that</td>\n",
              "      <td>The local government can deal with the problem...</td>\n",
              "      <td>'If some tragedies occur again ', ' relevant d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The author called Tommy 's parents in order to</td>\n",
              "      <td>help them realize their influence on Tommy</td>\n",
              "      <td>'blame Tommy for his failing grades', 'blame T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>It can be inferred from the passage that</td>\n",
              "      <td>the writer is not very willing to use idioms</td>\n",
              "      <td>'idioms are the most important part in a langu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How can we deal with snake wounds according to...</td>\n",
              "      <td>Stay calm and do n't move .</td>\n",
              "      <td>'Cut the wound and suck the poison out .'</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question  ...                                         distractor\n",
              "0                                Meals can be served  ...  'outside the room at 3:00 p. m.', 'in the dini...\n",
              "1           It can be inferred from the passage that  ...  'If some tragedies occur again ', ' relevant d...\n",
              "2     The author called Tommy 's parents in order to  ...  'blame Tommy for his failing grades', 'blame T...\n",
              "3           It can be inferred from the passage that  ...  'idioms are the most important part in a langu...\n",
              "4  How can we deal with snake wounds according to...  ...          'Cut the wound and suck the poison out .'\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Gsa4BNACwAD",
        "colab_type": "code",
        "outputId": "9c4c355d-d8ff-4ec2-96ad-244b426c7751",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What 'S the main idea of the text ?</td>\n",
              "      <td>The lack of career -- based courses in US high...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In the summer high season , Finland does nt se...</td>\n",
              "      <td>the sun is out at night</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>If you want to apply for Chinese Business Inte...</td>\n",
              "      <td>have to get confirmed at least twice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>That afternoon , the boy 's clothes were dry b...</td>\n",
              "      <td>nobody made room for him in the water .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Which of the following statements is NOT true ?</td>\n",
              "      <td>There are twelve countries in the World Wildli...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question                                        answer_text\n",
              "0                What 'S the main idea of the text ?  The lack of career -- based courses in US high...\n",
              "1  In the summer high season , Finland does nt se...                            the sun is out at night\n",
              "2  If you want to apply for Chinese Business Inte...               have to get confirmed at least twice\n",
              "3  That afternoon , the boy 's clothes were dry b...            nobody made room for him in the water .\n",
              "4    Which of the following statements is NOT true ?  There are twelve countries in the World Wildli..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIAVBF9THYEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = train.values\n",
        "test = test.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcRXG72zKZ24",
        "colab_type": "code",
        "outputId": "688648de-e2d8-4810-daeb-c3547a16f646",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31499"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8qHV2fyaUKw",
        "colab_type": "text"
      },
      "source": [
        "### Forming the dictionary for Question as key and Answer and Distractors as items"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k91lvT7iCwEC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answers = {}\n",
        "distractors = {}\n",
        "count = 0\n",
        "for x in range(train.shape[0]):\n",
        "  answers[train[x][0]] = train[x][1]\n",
        "  a=[]\n",
        "  for y in train[x][2].split(\", \"):\n",
        "    a.append(str(y[1:-1]))\n",
        "  distractors[train[x][0]] = a\n",
        "  count = count+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGbCwQcwCwIO",
        "colab_type": "code",
        "outputId": "d2b073d3-314f-4ddb-fdfd-16767544858d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "count"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31499"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4Uv4SguCwMj",
        "colab_type": "code",
        "outputId": "da2fa5fa-d2e7-4e3e-851a-70452a4cbebb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "distractors[\"Meals can be served\"]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['outside the room at 3:00 p. m.',\n",
              " 'in the dining - room at 6:00 p. m.',\n",
              " 'in the dining - room from 7:30 a. m. to 9:15 p. m.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZl2Pa2rakSh",
        "colab_type": "text"
      },
      "source": [
        "### Cleaning the Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuFoWHvpYHMy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(sentence):\n",
        "  sentence = sentence.lower()\n",
        "  sentence = re.sub(\"[^a-z0-9]+\",\" \" , sentence)\n",
        "  sentence = sentence.split()\n",
        "  \n",
        "  sentence = [s for s in sentence if((len(s)>1) or (re.match(\"[0-9]+\",s) is not None))]\n",
        "  sentence = \" \".join(sentence)\n",
        "  \n",
        "  return sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJQThFRIYUNP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clean all the captions\n",
        "a={}\n",
        "d={}\n",
        "for key , dist_list in distractors.items():\n",
        "  for i in range(len(dist_list)):\n",
        "    dist_list[i] = clean_text(dist_list[i])\n",
        "  answer=clean_text(answers[key])\n",
        "  key=clean_text(key)\n",
        "  a[key]=answer\n",
        "  d[key]=dist_list\n",
        "answers=a\n",
        "distractors=d\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uUZ-XWkaiIe",
        "colab_type": "code",
        "outputId": "9a791e4f-d6e5-40de-b09f-028730f70b14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "distractors[\"meals can be served\"]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['outside the room at 3 00',\n",
              " 'in the dining room at 6 00',\n",
              " 'in the dining room from 7 30 to 9 15']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jrr9cG2caqW_",
        "colab_type": "text"
      },
      "source": [
        "### Saving the Answers and Distractors to text file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FF7--dFCwQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"answers.txt\",\"w\") as f:\n",
        "  f.write(str(answers))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8YN6EdHCwUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"distractors.txt\",\"w\") as f:\n",
        "  f.write(str(distractors))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXwt6FqFQIT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = set()\n",
        "for key in answers.keys():\n",
        "  [vocab.update(key.split())]\n",
        "  [vocab.update(answers[key].split())]\n",
        "  [vocab.update(sentence.split()) for sentence in distractors[key]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xM1ebSkSXXe",
        "colab_type": "code",
        "outputId": "5db8ddbb-7272-43ed-e0c6-59502ac4a0f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(vocab))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21459\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRD4CTsUSat6",
        "colab_type": "code",
        "outputId": "7cd2090b-915f-4dd6-e86a-c5ba613d247b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "total = []\n",
        "for key in answers.keys():\n",
        "  [total.append(i) for i in key.split()]\n",
        "  [total.append(i) for i in answers[key].split()]\n",
        "  [total.append(i) for des in distractors[key] for i in des.split()]\n",
        "\n",
        "print(len(total))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "718584\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdQNVaXqSmiK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import collections\n",
        "counter = collections.Counter(total)\n",
        "freq_cnt = dict(counter)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWlrUccFVEla",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sorted_freq_cnt = sorted(freq_cnt.items(),reverse = True,key = lambda x:x[1])\n",
        "\n",
        "threshold =10\n",
        "sorted_freq_cnt = [x for x in sorted_freq_cnt if x[1]>threshold]\n",
        "total_words = [x[0] for x in sorted_freq_cnt]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOzIT4AdV0Sz",
        "colab_type": "code",
        "outputId": "74b9b2e2-223e-42da-8d6a-fccc112abba8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(sorted_freq_cnt))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4723\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FBWcZora5pW",
        "colab_type": "text"
      },
      "source": [
        "### Appending unique words for Start and End of sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2b0lwsMV282",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_distractors = {}\n",
        "for key in distractors.keys():\n",
        "  train_distractors[key] = []\n",
        "  for dist in distractors[key]:\n",
        "    dist_to_append = \"StartSeq \" + dist + \" EndSeq\"\n",
        "    train_distractors[key].append(dist_to_append)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dH0fx5l8eGet",
        "colab_type": "code",
        "outputId": "08731006-9d15-4883-be29-d4a499156640",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(train_distractors[\"meals can be served\"])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['StartSeq outside the room at 3 00 EndSeq', 'StartSeq in the dining room at 6 00 EndSeq', 'StartSeq in the dining room from 7 30 to 9 15 EndSeq']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCErV10beUj2",
        "colab_type": "code",
        "outputId": "3f5c5fb0-a77a-49a4-e88d-456263ae22ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(total_words)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4723"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSXMVMuroUXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_to_idx = {}\n",
        "idx_to_word = {}\n",
        "\n",
        "for i,word in enumerate(total_words):\n",
        "  word_to_idx[word] = i+1\n",
        "  idx_to_word[i+1] = word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWMtXVKeojNc",
        "colab_type": "code",
        "outputId": "e49e7256-2259-4579-ea03-729b8dd77775",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(word_to_idx)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4723"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqoVOt9-ojRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_to_idx[\"StartSeq\"]=4724\n",
        "idx_to_word[4724] = \"StartSeq\"\n",
        "\n",
        "word_to_idx[\"EndSeq\"]=4725\n",
        "idx_to_word[4725] = \"EndSeq\"\n",
        "\n",
        "vocab_size = len(word_to_idx) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hl4qITlrojW_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size= vocab_size+1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cl9Hp37udPa5",
        "colab_type": "code",
        "outputId": "6551ce61-cde7-46d6-92c0-8007f1136d09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab_size"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4726"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmR5G_7nojY6",
        "colab_type": "code",
        "outputId": "0d30fd80-447e-478e-b9fe-7e91f3999a44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_len=0\n",
        "for key in train_distractors.keys():\n",
        "  for dist in train_distractors[key]:\n",
        "    max_len = max(max_len,len(dist.split()))\n",
        "print(max_len)    "
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Go2KGjV0JmAD",
        "colab_type": "code",
        "outputId": "c8534021-5b58-42f8-8b11-a0fa1a3e4eec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_q=0\n",
        "for key in train_distractors.keys():\n",
        "  max_q = max(max_q,len(key.split()))\n",
        "print(max_q)\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "48\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwYOUI-IKKQE",
        "colab_type": "code",
        "outputId": "bbe0d6a2-5b6a-477a-81a3-e460d45a411c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_a = 0\n",
        "for key in answers.keys():\n",
        "  max_a = max(max_a,len(answers[key].split()))\n",
        "print(max_a)  "
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkpFrCAhbHyi",
        "colab_type": "text"
      },
      "source": [
        "### Generating Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuBKBU0Sojeq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_generator(train_distractors,answers,word_to_idx,max_len,batch_size):\n",
        "  X1,X2,X3,y = [],[],[],[]\n",
        "  \n",
        "  n=0\n",
        "  while True:\n",
        "    for key,dist_list in train_distractors.items():\n",
        "      n+=1\n",
        "      \n",
        "      question = key\n",
        "      answer = answers[key]\n",
        "      \n",
        "      \n",
        "      seqq = [word_to_idx[wordQ] for wordQ in question.split() if wordQ in word_to_idx]\n",
        "      question= pad_sequences([seqq],maxlen=max_q,value=0,padding='post')[0]\n",
        "      \n",
        "      \n",
        "      seqa = [word_to_idx[wordA] for wordA in answer.split() if wordA in word_to_idx]\n",
        "      answer = pad_sequences([seqa],maxlen=max_a,value=0,padding='post')[0]\n",
        "      \n",
        "      for dist in dist_list:\n",
        "        seq = [word_to_idx[word] for word in dist.split() if word in word_to_idx]\n",
        "        for i in range(1,len(seq)):\n",
        "          xi = seq[0:i]\n",
        "          yi = seq[i]\n",
        "          \n",
        "          xi = pad_sequences([xi],maxlen=max_len,value = 0,padding='post')[0] \n",
        "          yi = to_categorical([yi],num_classes = vocab_size)[0]\n",
        "          \n",
        "          \n",
        "          \n",
        "          X1.append(question)\n",
        "          X2.append(answer)\n",
        "          X3.append(xi)\n",
        "          y.append(yi)\n",
        "        if n==batch_size:\n",
        "          yield[[np.array(X1),np.array(X2),np.array(X3)],np.array(y)]\n",
        "          X1,X2,X3,y = [],[],[],[]\n",
        "          n=0\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CitEnZjpbNna",
        "colab_type": "text"
      },
      "source": [
        "### Importing the Glove Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgFrk3q6ojjP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f=open(\"./glove.6B.50d.txt\",encoding=\"utf8\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RV9YzLyNojnM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_index = {}\n",
        "for line in f:\n",
        "  values=line.split()\n",
        "  word = values[0]\n",
        "  embedding_index[word]=np.array(values[1:],dtype='float')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZogXCRf3ojst",
        "colab_type": "code",
        "outputId": "73e730ed-bc87-4642-887c-38d986492dfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "embedding_index['apple']"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.52042 , -0.8314  ,  0.49961 ,  1.2893  ,  0.1151  ,  0.057521,\n",
              "       -1.3753  , -0.97313 ,  0.18346 ,  0.47672 , -0.15112 ,  0.35532 ,\n",
              "        0.25912 , -0.77857 ,  0.52181 ,  0.47695 , -1.4251  ,  0.858   ,\n",
              "        0.59821 , -1.0903  ,  0.33574 , -0.60891 ,  0.41742 ,  0.21569 ,\n",
              "       -0.07417 , -0.5822  , -0.4502  ,  0.17253 ,  0.16448 , -0.38413 ,\n",
              "        2.3283  , -0.66682 , -0.58181 ,  0.74389 ,  0.095015, -0.47865 ,\n",
              "       -0.84591 ,  0.38704 ,  0.23693 , -1.5523  ,  0.64802 , -0.16521 ,\n",
              "       -1.4719  , -0.16224 ,  0.79857 ,  0.97391 ,  0.40027 , -0.21912 ,\n",
              "       -0.30938 ,  0.26581 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Fff1Gu6FCO5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getEmbeddingMatrix():\n",
        "  emb_dim=50\n",
        "  matrix = np.zeros((vocab_size,emb_dim))\n",
        "  for word,idx in word_to_idx.items():\n",
        "    embedding_vector = embedding_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      matrix[idx] = embedding_vector\n",
        "  return matrix    \n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JY3lOoKBGNFh",
        "colab_type": "code",
        "outputId": "2fa27ec4-82f7-4de1-d8a1-e8a64da23782",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embedding_matrix = getEmbeddingMatrix()\n",
        "embedding_matrix.shape"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4726, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAOQYk7qGNJc",
        "colab_type": "code",
        "outputId": "c0f7f868-3868-4e4c-e271-44807c6aadc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "embedding_matrix[4724]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PftdjmFDGNNU",
        "colab_type": "code",
        "outputId": "2217bd02-fceb-4d98-caf9-1adb76d30419",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(max_len)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDlptBUHbWE6",
        "colab_type": "text"
      },
      "source": [
        "## Architecture of the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQNtAJrUGNQC",
        "colab_type": "code",
        "outputId": "e3555bc1-6e3f-463e-fc35-ea1e04970b7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "input_dist = Input(shape = (max_len,))\n",
        "input_dist1=  Embedding(input_dim=vocab_size,output_dim=50,mask_zero=True)(input_dist)\n",
        "input_dist2 = Dropout(0.3)(input_dist1)\n",
        "input_dist3 = LSTM(256)(input_dist2)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3239: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmCZFgOfGNVf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ques = Input(shape = (max_q,))\n",
        "input_ques1=  Embedding(input_dim=vocab_size,output_dim=50,mask_zero=True)(input_ques)\n",
        "input_ques2 = Dropout(0.3)(input_ques1)\n",
        "input_ques3 = LSTM(256)(input_ques2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC6YXOlHLxC-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ans = Input(shape = (max_a,))\n",
        "input_ans1=  Embedding(input_dim=vocab_size,output_dim=50,mask_zero=True)(input_ans)\n",
        "input_ans2 = Dropout(0.3)(input_ans1)\n",
        "input_ans3 = LSTM(256)(input_ans2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1YnwmNgL7ox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder1 = add([input_dist3,input_ques3,input_ans3])\n",
        "decoder2 = Dense(512 ,activation = 'relu')(decoder1)\n",
        "outputs = Dense(vocab_size,activation= 'softmax')(decoder2)\n",
        "\n",
        "model = Model(inputs = [input_ques,input_ans,input_dist],outputs = outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhvvWJwINJTE",
        "colab_type": "code",
        "outputId": "853c51b7-3283-4bc9-d024-779cbdf53e28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 30)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 48)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            (None, 101)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 30, 50)       236300      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 48, 50)       236300      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, 101, 50)      236300      input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 30, 50)       0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 48, 50)       0           embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 101, 50)      0           embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 256)          314368      dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   (None, 256)          314368      dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   (None, 256)          314368      dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 256)          0           lstm_1[0][0]                     \n",
            "                                                                 lstm_2[0][0]                     \n",
            "                                                                 lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 512)          131584      add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 4726)         2424438     dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 4,208,026\n",
            "Trainable params: 4,208,026\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00kSJbA2NLY-",
        "colab_type": "code",
        "outputId": "c4b01d76-a51c-4f79-8b27-a66ef937d2c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "model.layers[3].set_weights([embedding_matrix])\n",
        "model.layers[3].trainable = False  \n",
        "\n",
        "model.layers[4].set_weights([embedding_matrix])\n",
        "model.layers[4].trainable = False  \n",
        "model.layers[5].set_weights([embedding_matrix])\n",
        "model.layers[5].trainable = False  "
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRj_GLEtN_wN",
        "colab_type": "code",
        "outputId": "37c295cc-0c90-40c3-e04c-04588e5cacf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer = 'adam')"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3FFbS9IUT9J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"model_99.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cS-do-LH7zh9",
        "colab": {}
      },
      "source": [
        "epochs=80\n",
        "number_of_ques = 128\n",
        "steps = len(train_distractors)//number_of_ques"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UR_wUu9oN__i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir model_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgPvQOVMN_4S",
        "colab_type": "code",
        "outputId": "7aef897b-52ac-4562-d953-a8375eb7ede8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(20,100):\n",
        "  generator = data_generator(train_distractors,answers,word_to_idx,max_len,number_of_ques)\n",
        "  model.fit_generator(generator,epochs=1,steps_per_epoch = steps,verbose = 1)\n",
        "  model.save(\"./model_weights/model_\"+str(i)+\".h5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "179/179 [==============================] - 249s 1s/step - loss: 3.0876\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 245s 1s/step - loss: 2.9993\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 245s 1s/step - loss: 2.9646\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 245s 1s/step - loss: 2.9271\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 245s 1s/step - loss: 2.8922\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 244s 1s/step - loss: 2.8583\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 245s 1s/step - loss: 2.8232\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 245s 1s/step - loss: 2.7880\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 246s 1s/step - loss: 2.7587\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 245s 1s/step - loss: 2.7274\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 245s 1s/step - loss: 2.6990\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 246s 1s/step - loss: 2.6735\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 245s 1s/step - loss: 2.6464\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 245s 1s/step - loss: 2.6222\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 245s 1s/step - loss: 2.5957\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 245s 1s/step - loss: 2.5750\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 245s 1s/step - loss: 2.5545\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 246s 1s/step - loss: 2.5355\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 245s 1s/step - loss: 2.5138\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 245s 1s/step - loss: 2.4972\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 245s 1s/step - loss: 2.4759\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 247s 1s/step - loss: 2.4600\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 246s 1s/step - loss: 2.4406\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 246s 1s/step - loss: 2.4232\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 245s 1s/step - loss: 2.4111\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 245s 1s/step - loss: 2.3909\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 246s 1s/step - loss: 2.3780\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 246s 1s/step - loss: 2.3647\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 245s 1s/step - loss: 2.3479\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 244s 1s/step - loss: 2.3340\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 245s 1s/step - loss: 2.3219\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 245s 1s/step - loss: 2.3068\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 245s 1s/step - loss: 2.2932\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 245s 1s/step - loss: 2.2797\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 246s 1s/step - loss: 2.2679\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 247s 1s/step - loss: 2.2536\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 246s 1s/step - loss: 2.2435\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 247s 1s/step - loss: 2.2314\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 246s 1s/step - loss: 2.2222\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 246s 1s/step - loss: 2.2101\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 246s 1s/step - loss: 2.2008\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 247s 1s/step - loss: 2.1903\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 246s 1s/step - loss: 2.1814\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 245s 1s/step - loss: 2.1694\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 246s 1s/step - loss: 2.1584\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 247s 1s/step - loss: 2.1461\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 246s 1s/step - loss: 2.1371\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 245s 1s/step - loss: 2.1296\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 246s 1s/step - loss: 2.1197\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 246s 1s/step - loss: 2.1130\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 245s 1s/step - loss: 2.1037\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 246s 1s/step - loss: 2.0980\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 246s 1s/step - loss: 2.0850\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 246s 1s/step - loss: 2.0757\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 246s 1s/step - loss: 2.0692\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 246s 1s/step - loss: 2.0610\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 246s 1s/step - loss: 2.0574\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 246s 1s/step - loss: 2.0487\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 246s 1s/step - loss: 2.0392\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 246s 1s/step - loss: 2.0339\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 246s 1s/step - loss: 2.0232\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 247s 1s/step - loss: 2.0153\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 246s 1s/step - loss: 2.0103\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 246s 1s/step - loss: 2.0026\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 246s 1s/step - loss: 1.9956\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 246s 1s/step - loss: 1.9913\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 246s 1s/step - loss: 1.9817\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 246s 1s/step - loss: 1.9762\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 247s 1s/step - loss: 1.9696\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 246s 1s/step - loss: 1.9645\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 247s 1s/step - loss: 1.9580\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 247s 1s/step - loss: 1.9505\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 247s 1s/step - loss: 1.9440\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 245s 1s/step - loss: 1.9397\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 246s 1s/step - loss: 1.9329\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 246s 1s/step - loss: 1.9285\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 246s 1s/step - loss: 1.9249\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 246s 1s/step - loss: 1.9138\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 246s 1s/step - loss: 1.9112\n",
            "Epoch 1/1\n",
            "179/179 [==============================] - 247s 1s/step - loss: 1.9077\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tEwZ12CfG1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"./model_weights/model_\"+str(i)+\".h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttQIvbKnbjom",
        "colab_type": "text"
      },
      "source": [
        "### Pre-processing for Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl94GpOJhpoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answers_t = {}\n",
        "count = 0\n",
        "for x in range(test.shape[0]):\n",
        "  answers_t[test[x][0]] = test[x][1]\n",
        "  count = count+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXVhJfx2lkL_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a={}\n",
        "for key , answer in answers_t.items():\n",
        "  answer=clean_text(answers_t[key])\n",
        "  key=clean_text(key)\n",
        "  a[key]=answer\n",
        "answers_t=a\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHaiH3yflkIZ",
        "colab_type": "code",
        "outputId": "e87af7cd-65ff-4222-d807-1b1d56d28f4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(answers_t[\"what the main idea of the text\"])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lack of water affects california crops\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GflgjB92VT3N",
        "colab_type": "code",
        "outputId": "608d3309-d4c4-46b7-af2f-5da4eea08c55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(answers_t.keys()))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10353\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dzn7rBAPVnX6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = pd.read_csv(\"Results9600.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ajiq0w1Vnd-",
        "colab_type": "code",
        "outputId": "c1fe03ed-048e-441b-b686-0aef66c7d778",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "result.head()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer_text</th>\n",
              "      <th>distractor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What 'S the main idea of the text ?</td>\n",
              "      <td>The lack of career -- based courses in US high...</td>\n",
              "      <td>'the students in london have made sense of imp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In the summer high season , Finland does nt se...</td>\n",
              "      <td>the sun is out at night</td>\n",
              "      <td>'the breakfast can not be late', 'there is cle...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>If you want to apply for Chinese Business Inte...</td>\n",
              "      <td>have to get confirmed at least twice</td>\n",
              "      <td>'be forced to join london', 'spend christmas w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>That afternoon , the boy 's clothes were dry b...</td>\n",
              "      <td>nobody made room for him in the water .</td>\n",
              "      <td>'neighbors to buy some bird', 'does he forgot ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Which of the following statements is NOT true ?</td>\n",
              "      <td>There are twelve countries in the World Wildli...</td>\n",
              "      <td>'the people in the world are not to be transla...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question  ...                                         distractor\n",
              "0                What 'S the main idea of the text ?  ...  'the students in london have made sense of imp...\n",
              "1  In the summer high season , Finland does nt se...  ...  'the breakfast can not be late', 'there is cle...\n",
              "2  If you want to apply for Chinese Business Inte...  ...  'be forced to join london', 'spend christmas w...\n",
              "3  That afternoon , the boy 's clothes were dry b...  ...  'neighbors to buy some bird', 'does he forgot ...\n",
              "4    Which of the following statements is NOT true ?  ...  'the people in the world are not to be transla...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VP63yKVfVnpv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = result.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqQbPWJeVnvH",
        "colab_type": "code",
        "outputId": "60e95348-0b76-46b6-b658-32cda3c10b6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "results.shape"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13500, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WmODfm_bsNk",
        "colab_type": "text"
      },
      "source": [
        "### Predicting the Distractors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpPqoWqpjcOk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhlAv9r4QNvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_distractors(X1,X2):\n",
        "  dists = []\n",
        "  for j in range(3):\n",
        "    in_text = \"StartSeq\"\n",
        "    for i in range(max_len):\n",
        "      sequence = [word_to_idx[w] for w in in_text.split() if w in word_to_idx]\n",
        "      sequence = pad_sequences([sequence],maxlen=max_len,padding = 'post')[0]\n",
        "      XQ = []\n",
        "      XA = []\n",
        "      XI = []\n",
        "      XQ.append(X1)\n",
        "      XA.append(X2)\n",
        "      XI.append(sequence)\n",
        "      y_pred = model.predict([np.array(XQ),np.array(XA),np.array(XI)])\n",
        "      \n",
        "      if(i<=1):\n",
        "        y_pred=np.array(y_pred)\n",
        "        y_pred = y_pred.argsort()\n",
        "        y_pred=y_pred[0][:]\n",
        "        y_pred=y_pred[len(y_pred)-1-j]\n",
        "      else:\n",
        "        y_pred=y_pred.argmax()\n",
        "      word = idx_to_word[y_pred]\n",
        "      in_text += (' ' + word)\n",
        "\n",
        "      if word == 'EndSeq':\n",
        "        break\n",
        "    final_dists = in_text.split()[1:-1]\n",
        "    final_dists = ' '.join(final_dists)\n",
        "    dists.append(final_dists)\n",
        "  return dists"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haZol5yIhpra",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "c01d2b5d-6479-4d3c-e0f5-d7c45d9d61d6"
      },
      "source": [
        "L = []\n",
        "for i in range(9600,results.shape[0]):\n",
        "  \n",
        "  question= clean_text(results[i][0])\n",
        "  answer = clean_text(results[i][1])\n",
        "\n",
        "#   print(question)\n",
        "#   print(answer)\n",
        "  seqq = [word_to_idx[wordQ] for wordQ in question.split() if wordQ in word_to_idx]\n",
        "  question= pad_sequences([seqq],maxlen=max_q,value=0,padding='post')[0]\n",
        "\n",
        "  seqa = [word_to_idx[wordA] for wordA in answer.split() if wordA in word_to_idx]\n",
        "  answer = pad_sequences([seqa],maxlen=max_a,value=0,padding='post')[0]\n",
        "  \n",
        "#   question = question.reshape((1,question.shape[0]))\n",
        "#   answer = answer.reshape((1,answer.shape[0]))\n",
        "  \n",
        "  distractor = predict_distractors(question,answer)\n",
        "  distractor = str(distractor)\n",
        "  distractor = distractor[1:-1]\n",
        "  results[i][2] = distractor\n",
        "  \n",
        "  if (i+1)%100==0:\n",
        "    print(\"questions done\",i+1)\n",
        "    res = pd.DataFrame(results)\n",
        "    res.to_csv(\"./Results\"+str(i+1)+\".csv\",header=[\"question\",\"answer_text\",\"distractor\"],index = None)\n",
        "    \n",
        "#   if (i+1)%1000==0:\n",
        "#     files.download(\"./Results\"+str(i+1)+\".csv\")"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "questions done 9700\n",
            "questions done 9800\n",
            "questions done 9900\n",
            "questions done 10000\n",
            "questions done 10100\n",
            "questions done 10200\n",
            "questions done 10300\n",
            "questions done 10400\n",
            "questions done 10500\n",
            "questions done 10600\n",
            "questions done 10700\n",
            "questions done 10800\n",
            "questions done 10900\n",
            "questions done 11000\n",
            "questions done 11100\n",
            "questions done 11200\n",
            "questions done 11300\n",
            "questions done 11400\n",
            "questions done 11500\n",
            "questions done 11600\n",
            "questions done 11700\n",
            "questions done 11800\n",
            "questions done 11900\n",
            "questions done 12000\n",
            "questions done 12100\n",
            "questions done 12200\n",
            "questions done 12300\n",
            "questions done 12400\n",
            "questions done 12500\n",
            "questions done 12600\n",
            "questions done 12700\n",
            "questions done 12800\n",
            "questions done 12900\n",
            "questions done 13000\n",
            "questions done 13100\n",
            "questions done 13200\n",
            "questions done 13300\n",
            "questions done 13400\n",
            "questions done 13500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaxI7HoFb1N7",
        "colab_type": "text"
      },
      "source": [
        "### Conversion of Final Results to Results.csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQHCk_clXyA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = pd.DataFrame(results)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rbzk2I_nXyPd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results.to_csv(\"./Results.csv\",header=[\"question\",\"answer_text\",\"distractor\"],index = None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Mg9Oa0rgzT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}